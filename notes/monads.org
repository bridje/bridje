Can we use the state monad inside a reducible?

this is all about context, really:
- writer - add to log
- reader - read from context
- state - manipulate state

reducible

how's about if we look at various solutions and see whether they're equivalent?
- monads in general
- passing in effects

with monads, you're essentially defining a whole load of possible operations, then defining a means of how they're composed
bear in mind, the monads ones also have the consideration that they're used lazily, which may well impact whether the solutions are isomorphic to ours

if we were to return an action from functions that were side effecting, we could replace it with callbacks, essentially
using it to write state is weird - we're essentially limited to one state variable (although that variable can itself be hellishly nested)
I think we can do everything that monads can here - because you can translate that kind of monads into callbacks, and then callbacks into eagerly passed/executed functions.
the only thing monads can do over this is decide whether to continue calling the next action - there's a sequentiality to them.
which monads are conditional like that? not many, I don't think? various error types, maybe, list monad - can we special case these ones?

transformers - used to create one monad out of many. example: tc monad - combination of error, reader, writer, state
state - in this case, a supply of type variables, we'd do with a local state var

maybe we can use one big materialized frame for this?

#+begin_src clojure
  (defmut !type-var)

  (get-type-var! )

  (with-mut [!type-var 0]
    )

  (let [!tvs (mut 0)]
    (mderef !tvs ))

  (ctx/defctx ctx Int)

  (:: (! (ctx)) Int)

  (ctx/update-ctx [ctx (->% (tl/update ))]
    ...)

  (with-fx [(def (ctx) foo)]
    )

  (def (analyse-expr form)
    (ctx))

  (ctx/defwriter log Str)

  (let [(:ctx/WriterResult val log) (with-log
                                      (log+ "hey")
                                      5)]
    ; val  =
    )

  (defmacro (with-log log-var & body)
    (let [sym-base (case log-var
                     (:SymbolForm sym) (:base-str sym))]
      ;; local mut? we're not defining anything here
      `(let [logs# (mut [])]
         (with-fx [(def (~(:SymbolForm (symbol (str base-str "+"))) log#)
                     )]
           (:WriterResult (do ~@body) )))))

  (st/defstate foo)

  (with-foo 5
    )

  (get-foo)
  (set-foo! )

  (updat )
#+end_src

writers/state is where it gets interesting - because monads give you finer grained control over which values of the writer are returned
even if I build a writer effect, I don't then have to use it and, if I don't, it doesn't affect the output
granted, =do= syntax doesn't give as much control, which seems to be the majority of use - but the Bridje way would be side-effecting based on what's run, Haskell way is based (strictly speaking) on what's returned.

local muts? we're relying on effects being at the global level - a function that we have to provide a definition for
why do I get the feeling that, if I solve local muts, there's something more general here?

local muts, I can pass into a closure, so they've got to form part of the typesystem, surely?
  although, maybe not, because we're saying that closures don't care about effects, why do they care about muts?
we're mainly after them for reducibles, but that's not the only reason - the writer 'with-log' above depends on them - and references them inside the closure.

aside: is this relevant/a dependency of the typeclass work?
yes, because if we want to base this all on monads first, we could do with arranging things nicely here first

local muts
are we back at this question of mut escaping again?

easiest implementation is mutable frames, can we get the typesystem to match that?
do we want to build it into the typesystem?
if we do, we need to ensure that the value can't escape out of the context - built-in?
not as clean as Haskell, where it's implemented on top - although I daresay it's optimised to fuck when it's spotted - this is fine too

compositional typesystem, each expr would need to specify which muts it accessed - what would the 'with-muts' built-in do?

I wonder whether this is about objects?
hypothesis: the /only/ time you need local muts is for closures
 - otherwise, you're in control of the control-flow, so you'd be able to use loop-recur, say

do we just go with 'all local vars are mutable'? whew.

all variables are mutable allows things like this:

#+begin_src clojure
  (def foo
    (let-mut [x 5]
      (fn []
        (doto x (update! inc)))))
#+end_src

which is most definitely effectful. so how do we keep track of this, either within the effect system, or within the type system as a whole?
the fn that's returned here depends on that mutable state there. we could expose a type variable, or something like that?

with reducers, using a common use-case:
#+begin_src clojure
  (def (. []) (reduce {init complete step} vec)
    (loop [state init
           seq (->seq vec)]
      (if-seq [(:Cons head tail) vec]
        (recur (step state head) tail)
        (complete state))))

  ;; explicit state
  (def (map f)
    {:init :Nil
     :step (fn [_state el]
             (:T2 (:Cons (f el) :Nil) :Nil))
     :complete (fn [s] :Nil)})

  ;; implicit state
  (def (map f)
    {:step (fn [el]
             (:Cons (f el) :Nil))
     :complete (fn [] :Nil)})

  ;; implicit state
  (def (partition-all n)
    (let [part (mut [])]
      {:step (fn [el]
               (set! part (conj part el))
               (if (= n (count part))
                 (let [yield part]
                   (set! part [])
                   (:Cons yield :Nil))
                 :Nil))

       :complete (fn []
                   (if-not (empty? part)
                     (:Cons part :Nil)
                     :Nil))}))
#+end_src

ok - so do we allow 'objects', or something like it? how would Haskell deal with this?
ST monad. has a state context type param which sets up a context, is bounded by the `runST` function.
we could either replicate this, or have a built-in with the same effect (at a cost of type system complexity)

obj would be a built-in:

#+begin_src clojure
  (:: (Reducer a b) )

  (def (partition-all n)
    (let-obj [{} (mut [])]
      ...))

  ;; type
  (:: (partition-all Int) (Obj [a] (Reducer a a)))

  (let-obj [rf (partition-all n)]
    )
#+end_src

hmm. local effects, instead?
local effects would be parameterised by a TV - =(mut a)=

#+begin_src clojure
  (defn mk-obj []
    (let [!foo (atom 5)]
      {:get-foo (fn [] @!foo)
       :set-foo! (fn [foo] (reset! !foo foo))}))

  (defn foo []
    (println "Hey!"))

  (defn foo [{:keys [println]} ...]
    (println "Hey!"))

  (def (partition-all n)
    (let [part (mut [])]

      {:step (fn [el]
               (set! part (conj part el))

               (if (= n (count part))
                 (let [yield part]
                   (set! part [])
                   (:Cons yield :Nil))
                 :Nil))

       :complete (fn []
                   (if-not (empty? part)
                     (:Cons part :Nil)
                     :Nil))}))

  (def !step (atom nil))

  (def (partition-all2 n vec)
    (let [{step complete} (partition-all 5)
          res (mut [])]

      (doseq [el coll]
        (set! res (concat res (step el))))

      (map (fn []
             (step ...))
           (range 3))

      (complete)

      res))

  ;; side effects and mutable values are two different things

  ;; passing functions in that use closures - IoC

  (:: (mut a) {:output-type a
               :mutations #{'part}})

  (:: :step {:type (Fn a (Seq b))
             :mutations #{'part}} )

  (:: (partition-all Int) {:type {(:step {:mutations #{'part}})
                                  (:complete {:mutations #{'part}})}

                           :mutations #{}})

  (:: (partition-all2 Int [a]) {:type [[a]]
                                :mutations #{}})
#+end_src

what needs to propagate that effect? the fn within it, likely has an effect of `get x` - but we essentially need to ensure that `x` cannot escape its bindings
let's say we call =foo=, that's essentially a read on that variable, which is a global var read, which is a genuine global effect - anything can affect it

back to Rust, potentially?

Rust would say that I'd 'moved' that variable into the closure, but then you can't move the variable into both closures -
and I'm not 100% sure how scopes behave when you do that - it becomes a globally scoped value?

this problem largely goes away if we make transducers deal with state explicitly - makes the surrounding code harder, sure, but doesn't then impact the type system

type of partition-all then has to include the type of its state, does the caller know about that? I guess it has to
so the type of :step is parameterised too - needs to

ok, ST.
gets away with mutable state because of the type variable 'escaping its scope'
if you want to access/mutate an STRef, you have to do it within the ST monad, which is then guaranteed to not escape.
can we do the same? it'd be a parameter on all FnTypes, I think. if you call them, you take on the marker

#+begin_src clojure
  (def (mk-counter)
    (let [cnt (mut 0)]
      (fn []
        (doto cnt (update! inc)))))

  (def (count-thingie)
    )

  (:: (. s) :xf-init (Fn s))
  (:: (. a s b) :xf-step (Fn s a (:T2 s (Seq b))))
  (:: (. s b) :xf-complete (Fn s (Seq b)))

  (:: (. s) :rf-init (Fn s))
  (:: (. a s) :rf-step (Fn s a s))
  (:: (. s b) :rf-complete (Fn s b))

  (:: (Transducer a s b) {(:xf-init s)
                          (:xf-step a s b)
                          (:xf-complete s b)})

  (:: (Reducer a s b) {(:rf-init s)
                       (:rf-step a s)
                       (:rf-complete s b)})

  (:: (combine (Transducer a s b) (Reducer b t c))
      (Reducer (a (+ (:T2 s t)) c)))

  (def (combine {xf-init xf-step xf-complete}
                {rf-init rf-step rf-complete})
    {:rf-init (:T2 (xf-init) (rf-init))

     :rf-step (fn [(:T2 xf-state rf-state) el]
                (let [(:T2 xf-state coll) (xf-step el)]
                  (:T2 xf-state (reduce rf-step rf-state coll))))

     :rf-complete (fn [(:T2 xf-state rf-state)]
                    (let [rf-state (reduce rf-step rf-state (xf-complete xf-state))]
                      (rf-complete rf-state)))})

  (def (map f)
    {:xf-init :Void
     :xf-step (fn [s el] (:More :Void (:Cons (f el) :Nil)))
     :xf-complete (fn [s] :Nil)})

  (def (map f)
    {:xf-step (fn [el]
                (:More (:Cons (f el) :Nil)))

     :xf-complete (fn [] :Nil)})

  (def (take n)
    {:xf-init n
     :xf-step (fn [n el]
                (let [sq (if (pos? n)
                           (:Cons el :Nil)
                           :Nil)
                      n (dec n)]
                  (if (pos? n)
                    (:More n sq)
                    (:Done n sq))))

     :xf-complete (fn [n] :Nil)})

  (def (take n)
    (let [n (mut n)]
      {:xf-step (fn [el]
                  (let [sq (if (pos? n)
                             (:Cons el :Nil)
                             :Nil)]
                    (set! n (dec n))
                    (if (pos? n)
                      (:More sq)
                      (:Done sq))))

       :xf-complete (fn [] :Nil)}))
#+end_src

Haskell's ST:
everything's within that ST monad
a lot of things within that are actions - e.g. =writeSTRef ref f= - this is the equivalent of our function
operations have to be composed together
#+begin_src haskell
  let y = do x <- newSTRef 5;
             return (modifySTRef x (+ 1), readSTRef x);

  runST $ do (inc, get) <- y;
             inc;
             inc;
             inc;
             get
#+end_src

=(inc, get) <- y= is creating the context, type is =ST s (ST s (), ST s Int)=

So we get very explicit control over the contexts. Equivalent in Bridje?
Let's say we assume the whole block's within the same context
global contexts can't exist - because you can't store the STRef at the top level, only the action to create one

again, compositional type system, so we should be able to type things like =(mut 5)= entirely independently of their surrounding context
likewise, the reading/writing of a mutable var
if we were to have =with-mut= we'd need to constrain the mut within that context - which we might be able to do if we can treat it as an effect
so the 'effect' behaves like it stores a whole load of mutable variables (optimisations aside)
the mutable context gets passed with the effect - means we don't necessarily need to have the env create the muts, nor manage them - seems like it's a ts concept
the context could also be a materialized frame - a mut creates a new variable in that frame
can we make this implicit, with some kind of escape analysis?

#+begin_src clojure
  (transform (range 10) (combine (take 5) ->vec))
#+end_src

the =(take 5)= being provided to =combine= has a mutability tv - the call to transform needs to realise that the mutability can't escape, so it shouldn't have the tv attached

=(:: (combine (Transducer a b) (Reducer b c)) (Reducer a c))=

We don't want to have to include =s= in the type param of Transducer - because it isn't /necessarily/ mutable - likewise =combine=, likewise =xf-step= - so none of these know about it
it's the specific implementation that's mutable.
in Haskell, though, =combine= would have to know about the monad
should combine say that it's as mutable as its params?

maybe each of the types has a mutability param? monotypes? args? just fntypes?

Clojure's =take= isn't mutable in itself - it returns a function that is - this is slightly different with the implementation above

ideally the type system would be powerful enough to look at the call to =transform= and realise that mutable state can't get out of there

about =take= - it's specifically the call to =(:xf-step (take 5))= that's mutating things - does that impact how we think about it?
I'm wondering whether we do have some primitive-level objects for stuff like this - we can say that an object is free to mutate any of its fields
objects can then implement typeclasses - they're essentially one-valued variants
but then we're kinda creating an interface/object system rather than a typeclass one - can we unify the two?

can we un-invert the control, so that the transducers/reducers can use loop/recur? or /seem/ like they're using loop/recur?
not a massive fan of this, seems like it might be a bit hacky

let's say it does have a context - that mutable variables are provided by the frame - actually, we'd want the frame as close as possible to the usage so that it could be GCd

step back - we're doing this because we don't want to explicitly pass the state around - which might not be so bad an option
- except that all transducers then need to know about state
- you can't then pass something stateful to something that doesn't know about its state (you can with effects, because static binding)

so can we do it with that same static effect passing?

what about if the effect could be instantiated?

alrightey, a lot of weekend reading
particularly, that effects pretty much mandate that we move to a CPS compiler - at least, if we want the degree of control that Koka has
effects can have several different forms - none (never resumed), tail, scoped (resumed within the body), or general (resume treated as a first class value)
resources? instantiate the resource and pass it around?
n.b. let-polymorphism - only generalise types that are total

can we have a heap of resources that get allocated/deallocated? maybe there's then some overlap between us and Rust's ownership?
what's the types of the effect handlers? what do they look like now, in Bridje? now that we're talking about changing one hell of a lot of the underlying semantics

also seems like Koka's actions are lazy - they're not executed until they're eval'd by a handler - and even these handlers might still return actions if there's more effects to be handled

Koka needs an 'umbrella effect' which is responsible for managing the scope of resources - for state, this is 'heap', which has no operations


#+begin_src clojure
  (:: (! (read-line)) Str)
  (:: (! (println Str)))

  (def (! (read-line))
    )

  (def (! (println s))
    ...)

  (handler (def (! (read-line))
             )
           (def (return )))

  (def (my-cli)
    )

  (handle )

  (:: (! (.read-line)) Str)

  (with-obj [(def x 5)]
    )

  (defobj (input-stream is) []
    (def (.read-line)
      )

    (def (&finally )
      ))

  (defhandler foo-handler
    (def (&return )
      ))

  (def (test-foo)
    (-> (with-handler foo-handler ))
    (with-obj [obj (input-stream )]

      ))
#+end_src

so we want to move to actions? first class actions and first class handlers/objects seem to be more powerful.
is constructing an object an action?
first class actions - why?
it's only a function call away, after all
in theory, we can re-use handlers if they're first class - we could pass a handler value to a function
that said - we can generate a macro that'll apply the given handler - likely means that the type system then doesn't need to care about handlers
what's the type of a handler? action -> value/action most likely
then it doesn't need a built-in to deal with the action - it's 'just' another function invocation.
(I'd be surprised if we didn't need a built-in to create the handler)
can handlers be thought of as maps of functions? possibly. we'd want a built in to create them, even if they did /look/ like maps

#+begin_src clojure
  (handler (def (println s)
             )

           (def (&return x)
             ))

  (def println-handler
    (handler (def (println ))))

  (def (println s)
    ...)

  (with-fx [(def (println )
              )])

  (:: foo-handler (Handler #{println} (Fn a [a])))
  (:: foo-obj (Object #{.read-line }))

  (:: (.read-line a))

  ;; only reason I've seen for 'return' so far is state and ndet

  (:: (! (println Str)))

  (:: (! (.println Str)))

  (:: MyObj {.println})

  (with-obj [w (let-obj [w (Writer/new ...)]
                 (def (.println s)
                   (Writer/.println w s)
                   (&resume :Void w))

                 (def (&finally)
                   (Writer/.close w)))]

    (.println w "Hello world!")
    )

  (def-handler (state-handler s)
    (def (get) (&resume s s))
    (def (set x) (&resume :Void x)))

  (def (handler s)
    (let-handler [s s]
      ))

  (with-fx (state-handler 5)
    )

  ;; systems?

  (def (println-caller w s)
    (with-obj [w (obj [] [])])
    (w.))
#+end_src

object methods are this weird cross between typeclasses and effects - it's effectful, but also polymorphic in the value that's passed
chances are it's going to be a whole load of the same types of object passed down, but in reality we don't need to care about that - the caller only really cares that there's an implementation it can use
in this case, we're going to need to know that the function's effectful - so, really, it's both an effect and a polymorphic function.

we probably also want to be able to pass in the mocked object at this point, rather than the effect.

so maybe the method is something like =(w.println "Hey")= using the =w= from ... a type sig?
is the object case the general case of the normal effect case, only that the normal effect case refers to a singleton global object?

Koka seems to give you a different function to call through to different effect resources, can we do that?
for some reason I'm pretty keen to avoid this, but fundamentally we are talking about calling a method on a resource

typeclasses.
this is different to typeclasses though - the functionality is on the object itself. seems like resource functions /should/ be handled separately.
declared with a dot at the start, say; implemented with methods on the object, duck typed, almost
we'd type it that we require an object with enough methods.
we're essentially talking a product type, so there's maybe some overlap with records here - can these objects be seen as a record of methods?
record of methods would mean we could add to them, potentially, merge them, etc

those objects then need to be constrained within a 'heap' effect - this determines when they can be finalised - is it better to do this with a Rust ownership model?
with state, we want to remove the effect; with most others, we don't - the methods themselves will be side-effecting
  maybe it's the opening of the file/connection we care about, we don't really care about how far through the file they read
  so the initial creation of the resource is the side effect, not the individual read functions
  in the case of println, though, we don't care about the opening of the writer - we care about who writes to it.
  it'd likely be up to the user to determine the difference between them

can all of these share a common heap? what delimits the heaps?

actions. so these would be first class too, rather than just being the body of a with-fx expression. this'd likely make with-fx a function
we've got a slight difference here given that our effects are lexically bound over a =fn= expression, which probably makes it significantly different to Koka.
Koka deals with 'this effect plus anything else the function you passed me calls', which we don't need to - because those functions are treated as pure in Bridje.
going to actions would mean having the function returning a closure - but then there's no difference to it returning a closure and just accepting another arg (as it does currently)
maybe there is - you can pass the former around as an action awaiting handlers, but not the latter
latter means you have to deal with it as macros, not a problem for us but might make these things harder to compose
tbh - it doesn't really - we define a top level name for it and then it deals with the effects anyway

/the choice of resolving handlers lexically pretty much means we can't have first-class actions/
I don't think it precludes us from having first-class handlers though, which is possibly where the value lies

with actions:
- functions with effects would be a specific different type - meaning we couldn't just pass them around

- (also its type classes, but that makes it rank-n polymorphic anyway, funsies)
- which pretty much means that we need to separate out the effect args from the typeclass args - because the former are dealt with by lexical scope, the latter by dynamic

without actions:
- actions cannot be first class - it has to be that the top-level vars have the extra parameter - when resolving it, we need to set the effect handlers that are in play for that call
- does that mean we can't have the resumable handler bodies? we'd then need to CPS up the intermediate functions, which presumably would have no idea that they'd be being called within a resumable call
- so pretty much every call node has to deal with the fact that it /could/ be returned asynchronously/not at all
- shouldn't be too much of an issue in Graal - one asynchronous call would (I think) flip us back to the interpreter and force us to re-compile the whole stack
- could/should we mark certain effects as synchronous/asynchronous? i.e. in order to use =&resume= out of tail position we'd need to allow it at the top
- can we get away with that on a handler-by-handler case? i.e. we assume at the top of the function that we're all either tail recursive or exceptional?
- vast majority will fit into these two camps, so it will only be the functions with proper asynchrony that need to resort to breaking the assumption
- problem with resolving those effectful functions every time? in fact, does it apply to /all/ effectful GV calls?
- if we have an effectful GVE within the function body, we need to be prepared that it may well need to be converted into CPS form
- at what granularity do we convert the call? it pretty much needs to be, on each call, which node it uses, I think?
- then, if it's /ever/ called with asynchronous effects, we have a check at the top of the function
- maybe we deliberately have two versions of the function available, as part of BridjeFunction, so that the optimisation/invalidation is done by the /caller/
- a third/fourth variety if we need to curry the function - or maybe we can do the currying separately. probably an idea to.
  - yeah - ideally we'd only need to curry the function if we knew it was getting passed as a value - a CE with a GVE as the first arg shouldn't need to
  - the currying function could be generic - it 'only' needs to capture the effect environment and ensure that's passed through
  - could we combine this with the lexical environment? lexical environment's only used for FnExprs - they're two separate cases
  - FnExpr - holds a reference to a materialized frame, from ... somewhere?

with effects, would we need to specify a different effect for each type of exception?
we're already doing that, albeit with variants - and this way, it means =throw= doesn't have to be a special form

#+begin_src clojure
  (:: (! (bad-req)))

  (def (process-req req)
    (if (valid? req)
      {:http/status 200, :http/body "foo"}
      (bad-req)))
#+end_src

more granular this way - we can handle certain types of exceptions all in one
but does mean that (if the call is parameterised) we have to handle all the different error cases, not just the ones that are actually thrown
if we don't want that, we split the effect up into multiple different effects
implementation-wise - we need to be able to bubble the exception up to exactly where it needs to be handled
- all exceptions would have to throw the same Java ControlFlowException, it'd need to be the handler that checked whether it's the right one for the job.

can we, for each call node, keep both the direct and continuation version?
we could certainly translate the lot into a CPS expr tree - the CPS part isn't tied to Graal, necessarily
how's Graal going to deal with CPS by default? I'm guessing it's not a massive fan of the materialized frames, given how much it says about not materialising unless you have to.
I reckon, treat it as tail call by default, then, when we get into the handler, chuck an oh-fuck-cps-please exception,
  which drops back to the interpreter, recompiles the caller, materialises the frame, etc

actually, can we go back from CPS version to direct?
  the difference in nodes isn't massive, I don't think
  I don't reckon we'll be able to do this with arbitrary continuations
  we're going to have to know that whatever's in the continuation is tail recursive
  let's say we've got
  #+begin_src clojure
    (def (foo x y)
      (+ (* x y) 2))

    ;; cps

    (def (foo x y k)
      (* x y (fn (z)
               (+ z 2 k))))

    [:fx-call {:f *
               :args [[:lv x] [:lv y]]
               :cont [:fn [[:lv z]]
                      ]}]
  #+end_src

  abort.

let's say we've got the direct calling style, (top foo, above), and the inner =*= is effectful
well, there's a few possibilities here: it could be an effect-fn, it could be effectful, it could be effect-free.
do we need to handle the former two differently?
they've both got the potential to need to be asynchronous, depending on the asynchrony of whatever's passed in the effect map
they've both got the need to be potentially asynchronous - even if the effects passed to foo are all tail calls, we can override the effect within the body with something asynchronous and that unwinds the lot
bugger.

can we write the whole lot as CPS and then optimise the tail call case?
what we don't want to end up doing is materialising the whole stack.
I reckon we're going to be labelling certain effects as 'potentially asynchronous' which then unwinds the whole stack around them
that does then mean that it's the declarer of the effect that needs to make that call, not the implementer (if indeed they're different)
OTOH, async IO's becoming a lot more popular - it might be that we /want/ asynchronous for a lot of effects
well, there's going to be a number of effects that aren't.
coming back to the assumption compilation - can we write it directly and then the asynchronous handler throws an exception, chucks us back up and then recompiles the call stack under CPS.
exception would be caught by the handler itself - but would need to impact the whole call stack, although only from that call
needs to materialise (and clone) each of the frames on the way up - possibly partially - we've already run /some/ of the frame directly, need to run the rest in the continuation
don't know how the types work here in the handler - the handler still needs to return /something/, presumably
and if it's async, we can't guarantee that it'll ever return - it might get stuck in a queue that's never processed, for example.
do we want to allow that? at least, not without massive caveats within the type system

we can spot async calls and mark them? higher order functions could be fun here - the callee is 'as async' as the function passed to it
is the return type of the handler 'async' somehow? then the callers would also have to be async...

let's write out some async handlers as more specific types:

#+begin_src clojure
  (:: (wait! Int))

  (:: (await! (Fn )))

  (def (wait! timeout-ms)
    (Async/wait timeout-ms &resume))

  (let [res (with-fx [(def (wait! timeout-ms)
                        (Async/wait timeout-ms &resume))]
              (let [x (wait! 100)]
                "Hello"))]
    (str res " " "World!"))
#+end_src

higher order functions and async.
interop's going to be problematic there - we can't do async here unless the surrounding framework supports it
so maybe we can return `Async a` from a function if we think it's possibly async - can we tell?
it's not `async a` specifically - because callers should deal with it regardless of whether it's async or not
it's `a` with an async flag?
unless we want a specific 'await' call? do we need one, can we infer it?

a lot of these functions are going to be 'as async as the events/functions passed in' - can we deal with these statically in the same way as we deal with normal effects?
caller can tell which ones are async, can't it?
it is going to impact the callee, because the callee's going to need to know how to unwind the stack if it's an async call
if we did have a separate =await= special form, that would do it
  effects would need to declare `Async a`
  anything call those effects would need to 'await' them
  we wouldn't support the 'ambiguous' effects, that call the resume function multiple times
  if we do async separately, it doesn't need to be part of the effect system at all - we can make the effect system completely synchronous

types-wise - should we do the polymorphic effects as per all the literature - seems weird that we're doing it differently.
we're doing it differently because we want the effects of a closed-over function to be handled solely by the lexical scope.
this is because of interop - we want to be able to pass functions to Truffle interop without the host knowing about any effects.
hosts/guests are going to need to know about the calling convention of polymorphic functions too. maybe we need to just accept they need to know?
what about the issue of passing it over futures? we can possibly specify a special form, but that's /another/ special form
can make effectful/polymorphic functions closures instead - they have to be called first with the effects/polymorphic params first
ideally not - we don't want to do this the whole time.
can we wrap functions up that we know are being passed to interop fns?
we don't want to be able to pass unresolved polymorphic functions to interop - they won't know how to resolve the polymorphism.
in fact, this is going to cause problems even within Bridje - because when we pass a polymorphic function to a function that doesn't expect one, it's not going to know about needing to supply extra params.
haha, good fun.
think this is a special case of the more general rank-n calling convention - in this case, we need to be able to pass /part/ of the dictionary.
I'm coming around to the idea of always passing effects/poly as the first arg, will make life significantly easier
what about functions that escape their with-fx binding? does it matter if we're treating it as an action?

seems like other languages with delimited continuations are wrapping them up in an explicit block, and typing them as such

we might be able to completely ignore it through the vast majority of the program - using the assumption that a function is as async as the effects you pass in
an async handler will then want to unwind the stack - which apparently we have access to via the =iterateFrames= functionality
each of the nodes in the stack will then be asked to CPSify itself and preserve its frame
if we hit a foreign frame, we're going to have to decide what to do at that point - return a function accepting a callback, perhaps?
or, at system boundaries, we wrap such functions in something blocking (unless they're given an extra callback param?)

we wrap async with-fx blocks in an async effect that has to be explicitly handled - chances are with a call to =await= that puts us back in async mode

#+begin_src clojure
  (def )
#+end_src

going back to the decision around first class actions - can we go back on that decision not to allow them?
we'd need to specify that there are two sources of effects in that function - from the lexical environment and from the dynamic environment
chances are the two are the same, if they're called from the same place?
unless we make it a specific call to satisfy the effects lexically, like clojure's =bound-fn=
it's going to be the same in all cases, unless the function escapes its lexical scope. in that case, do we want the lexical scope to provide the effects anyway?
it's a bit of a gotcha if the code behaves differently when the callee's run on one thread vs many - although that effect should also bubble up.
crazy idea - maybe it wouldn't - although this would mean being able to infer that any parallelism doesn't change the behaviour of the function.

first class actions - this would mean that the actions themselves are lazy - they wouldn't be called unless something at the top-level evaluated them.
would mean that any functions that did escape the lexical scope would need to be explicitly marked, just in case the effects were to be overridden
=with-fx= would still be a special form, but it could be relatively easily typed - takes an action with 'X, Y and other effects', a handler handling X+Y, returns an action
from an evaluation

threads - need to be careful regarding state between threads - how are the handlers going to work?
also resources between threads - Leijen's written a bit on this in his resources paper
I wonder whether bits of this go away when you talk about actions - you run the actions in different threads and it creates different instances of the handlers.
can't create different instances of the resources though - might be creating multiple real-world connections, for example.

#+begin_src clojure
  ;; not really `let-resource`, but need `let-` prefix for the indentation
  (def (open-conn! {...})
    (let-resource [conn (open-conn! ...)]
      (def (&init)
        )

      (def (&finally)
        )))

  (with-resources [])

  ;; needs to only run any side effects within a handler block

  ;; two parts to this - params and the actual resource
  ;; wonder if, for resources, we make the first param special
  ;; some of the parameters will need to come from the surrounding function
  ;; some will want to be defined by the resource itself
#+end_src

ideal properties of the syntax
- change effect syntax to have =!= wrap the output type
- handlers are first class, actions aren't - we can easily make actions first class by wrapping them in =fn=
  - so we need to be able to define these and assign them
  - the type system needs to be able to handle them (haha)
  - handlers have parameters, parameters all have an initial value
  - handlers handle a number of effect functions
  - handlers can alter the return type of the action
- resources are the same as handlers, but callers have to pass the reference explicitly
  - resources might also have parameters
- =with-fx= takes a handler and an action form
- would be nice to say that functions are pure if neither they nor their callees call any effects
-

#+begin_src clojure
  (:: (.send ByteStream) (! Unit))

  (:: #{(.send a)}
      (open-conn! )
      (! a))

  (:: (get!) (! v))
  (:: (set! v) (! v))

  (def (state-handler v)
    (let-handler [v v]
      (def (get! k)
        (k v v))

      (def (set! v k)
        (k v v))))

  (def (update! f)
    (set! (f (get!))))

  (with-handlers [(state-handler 5)]
    (set! (inc (get!)))
    (update! inc)
    (update! (->% (+ 2)))
    (update! (# (* % 2)))
    (get!))

  (Resource #{.get-conn})

  (Resource h #{.get-conn})

  (def (connection url)
    (let-resource []
      (def (&init k)
        (k (Connection/open url)))

      (def (.get-conn conn k)
        (k conn))

      (def (&finally conn)
        (Connection/.close conn))))

  (with-resources [conn (connection "foo")]
    (with-handlers [(def )
                    ])
    )

#+end_src

- we're going to want to put these resources in systems
  - which begs the question of how you compose resources - seems simple enough to write a resource that keeps other resources
  - make it a stack
- well, system is a resource in itself - maybe we give the runtime a resource and tell it to manage it?
  - ha - we may not need to - if the resource waits on a stop callback!
  - obviously can't guarantee that the stop function's going to get called - but that's got to be on the developer

- type of the resource is something that handles all the effects
  - do we distinguish between things that create resources and open resources? think we have to - the former are way more reusable than the latter
  - type of the resource needs to include the 'type of it's scope' (however that works)
  - what properties do we need of that type?
  - need to be careful with how it's stored.
  - unless we go the Rust route of ownership with resources - with resources, it makes sense, it's justifiable
    - if you put the resource in a variable, you have to lose ownership - borrow it back if need be
    - can follow most of the Rust ownership rules, after that
    - might be that we don't then need to worry about an explicit block for resources?
    - as in, we can tell when they're no longer used, from when they drop out of scope
    - might also mean that the resource can only be used from one thread at once?
    - that'd mean the closure, or any other data structure the resource were to be put in, would also become a resource
    - means we'd want any data structure containing the resources to be a resource too
    - and then it's turtles all the way
    - we'd want to keep the vast majority of values free to be passed around - which they would, tbh
    - ah, but then, immutable copies - things like conj/assoc/merge would need to take ownership of both the vector and the element
    - polymorphic data-structures would not be able to take ownership of their values - but then you could prove they didn't
    - how much of that do we want to expose to the users? I suppose it's only really an issue for polymorphic functions
    - you have to take ownership of the whole of the data structure, or none of it, I suspect?
    - maybe not within the function. actually, yeah, because accessors will need to too. although they'd just be borrowing (by default?)
    - but then Rust has a whole load of rules etc, moving rules into closures etc
    - two accessors from the same object though?
    - maybe closure can be treated like a struct - it essentially stores values - so if a value is moved into the closure it can no longer be used
    - we don't have to worry about copy semantics - we're only concerning ourselves with resources (which cannot be copied)
    - even though ownership is only going to be used for resources, it's still going to impact most (if not all) of the type system
    - can we simplify it? we likely don't need mutable vs immutable reference types
    - we likely need borrowing - passing a reference to another function, for example - this means that we can't store that resource anywhere

  - alternative is we give the power to the user to manage it themselves - it's not too difficult but saves a lot of complexity in the lang.
    - what do we have to add if we don't add ownership? with-resource block, nothing too tricksy - and that'd need to handle the CPS
    - can we add it later? possibly...

ok, so back where we started - what do resources look like?
someone the other day said about objects being 'just' a map - that's probably not a bad shout.
would have to tag certain functions as being resource functions, that could be interesting - dot prefix, to keep similarity with Clojure?

#+begin_src clojure
  ;; Happy with these two
  (:: (.read-bytes! Int) (! (JArray JByte)))
  (:: Connection {.readBytes})

  (def (conn url)
    (object
      (def (init k)
        )

      (def (.read-bytes! this n k)
        (k {} this))

      (def (finally this)
        )))

  (with-objects [conn (conn url)
                 ]
    (.read-bytes! conn))

  (:: (transform-conn {.read-bytes!}) (! [Thing] #{.read-bytes!}))

  ()

  ;; properties of the constructor:
  ;; - need to name the fields of the resource
  ;; - maybe need to initialise them (lazily)
  ;; - need to refer to them by name in the other functions
  ;; - need to be first class - need to be able to pass resouces around, both initialised and uninitialised
  ;; - need to have those resources used within a context - so that state can be elided
  ;; - need to have types for the resulting objects
  ;;   - maybe 'object' isn't so bad, 'obj' is quite an unambiguous abbreviation

  ;; unless we remove state from this for the time being - doesn't seem like a resource in the same way

  ;; maybe handlers are just objects?
  (def handler
    {(def (&init k))})

  (:: (conn Str) (! {.read-bytes!}))

  (let-handler [foo]
    (def (conn url)
      (object
        (def (.read-bytes! n k)
          (k ...)))))

  ;; this syntax is looking promising, maybe we need to figure out how to do state params?
  (with-obj [foo (obj (def (&init k)
                        (k this))

                      (def (.read-bytes! this n k)
                        )

                      (def (&finally this)
                        ))]
    )

  (with-fx [(fx (def (&init k)
                  (k 5))

                (def (&return x k)
                  ))])

  (with-fx [(fx (def (.read-bytes! f n k)
                  (k (f n))))]
    )

  ;; ideas for state params

  (let-fx [x 5]
    (def (get k)
      (k x x))
    (def (set x k)
      (k x x)))

  (let-fx [x 5]
    (def (get k)
      (k x x))

    (def (set _ k x)
      (k x x)))

  (with-obj [foo (let-obj [this]
                   (def (&init k)
                     (k foo))

                   (def (.read-bytes! n k)
                     (k bytes this))

                   (def (&finally k)
                     (k)))]
    ...)
#+end_src

ok, reasonably happy with this syntax and behaviour for now

but really, we want to be consuming and using these resources in a predictable way
not sure we can turn all resources into the generator pattern, though

regarding effects - all of the objects contain effectful functions anyway - they can /all/ be replaced, in theory
so the effects need to be kept separately for objs and fxs - depending on whether we use the defaults or not?
effects behave differently between fx and obj though - feels like one's defined at the leaf, the other only at the root
if I call an effect, wherever I call it, it's either going to be handled by the default effect handler (global), or any intervening handler
if I call an obj fn, there is no default handler, it's going to be handled by the obj itself or intercepted by a handler higher in the stack
so maybe we don't want to be able to define inline objs - maybe those have to be defined at the top level too in order to work in the effect system
back to the drawing board, yay
if we want to define objs at the top level then it means we're naturally grouping at the top level, which is something we don't do with other lang constructs
let's say we were to define objects at the top level, though:
with handlers, it's the inner-most implementation that wins, maybe we give it the option of calling the outer implementation
with objects, we'd probably still make it the inner-most implementation, given we want to mimic the behaviour of handlers. can't give it access to the outside, though, because it might not exist

conclusion: don't think we need to define objects at the top level, think that's fine
doesn't matter if methods aren't explicitly handled outside

things still to consider:
- type system? think we're nearly there
- finalisation? we're assuming that the callback's called exactly once
- sequencifying the resource? do we need to, or is this a pattern above?
- how does async work within the type system - do we have to handle it separately if we spot a handler can be async?
